{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8908c64-65a9-4715-b651-9455b875c354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "from scripts.graph_utils import create_heterograph\n",
    "create_heterograph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c254bc4-744c-43c5-b9f8-6d002e666842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "from scripts.model import EntityClassify\n",
    "from scripts.dataset import HinNodeClassification\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import time\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "DATASET_PATH_EN = 'graphs/heterograph_en.bin'\n",
    "DATASET_PATH_ES = 'graphs/heterograph_es.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3662413-4077-453c-81e7-304d32034886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please input 'en' for English or 'es' for Spanish: es\n"
     ]
    }
   ],
   "source": [
    "language = input(\"Please input 'en' for English or 'es' for Spanish:\")\n",
    "if language == 'en':\n",
    "    DATASET_PATH = DATASET_PATH_EN\n",
    "else:\n",
    "    DATASET_PATH = DATASET_PATH_ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff17623e-17cf-4b37-a32c-3f239092f31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hg = HinNodeClassification(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fa6ac1b-cdbb-4cb9-887f-54b9491a032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = hg.g\n",
    "category = hg.category\n",
    "num_classes = hg.num_classes\n",
    "train_mask, val_mask, test_mask = hg.get_idx()\n",
    "labels = graph.nodes[category].data.pop('labels')\n",
    "h = graph.ndata['h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc241cb1-8523-4105-86f2-bc598680d75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeSpace(data={'h': tensor([[ 0.0312, -0.0144,  0.0011,  ...,  0.0223, -0.0072,  0.0065],\n",
       "        [ 0.0206, -0.0122,  0.0175,  ...,  0.0302, -0.0187,  0.0142],\n",
       "        [ 0.0209, -0.0159,  0.0052,  ...,  0.0258, -0.0112,  0.0078],\n",
       "        ...,\n",
       "        [ 0.0431, -0.0145,  0.0035,  ...,  0.0199,  0.0015,  0.0048],\n",
       "        [ 0.0187, -0.0015, -0.0085,  ..., -0.0022,  0.0005,  0.0097],\n",
       "        [ 0.0122, -0.0032, -0.0064,  ...,  0.0086, -0.0056, -0.0052]])})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hg.g.nodes[category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a363e8ef-b69c-42f3-b31d-c772d11d8964",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EntityClassify(graph,\n",
    "                           hg.in_dim,\n",
    "                           num_classes,\n",
    "                           num_bases=-1,\n",
    "                           num_hidden_layers=1,\n",
    "                           dropout= 0.3,\n",
    "                           use_self_loop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "822039ea-81a7-4218-945d-f5f71f5e7414",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  optimizer = th.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.l2norm)\n",
    "optimizer = th.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740e5efd-bab9-4e44-987b-822b538cfbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\base2\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "D:\\Anaconda\\envs\\base2\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Train Acc: 0.5069 | Train Loss: 0.6932 | Valid Acc: 0.4375 | Valid loss: 0.6933 | Time: nan\n",
      "Epoch 00001 | Train Acc: 0.5625 | Train Loss: 0.6837 | Valid Acc: 0.5000 | Valid loss: 0.6926 | Time: nan\n",
      "Epoch 00002 | Train Acc: 0.7083 | Train Loss: 0.6704 | Valid Acc: 0.5000 | Valid loss: 0.6861 | Time: nan\n",
      "Epoch 00003 | Train Acc: 0.7778 | Train Loss: 0.6563 | Valid Acc: 0.5625 | Valid loss: 0.6791 | Time: nan\n",
      "Epoch 00004 | Train Acc: 0.7986 | Train Loss: 0.6409 | Valid Acc: 0.6250 | Valid loss: 0.6718 | Time: nan\n",
      "Epoch 00005 | Train Acc: 0.7986 | Train Loss: 0.6242 | Valid Acc: 0.6250 | Valid loss: 0.6729 | Time: nan\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "print(\"start training...\")\n",
    "dur = []\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    if epoch > 5:\n",
    "        t0 = time.time()\n",
    "    logits = model(h=h)[category]\n",
    "    loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    t1 = time.time()\n",
    "\n",
    "    if epoch > 5:\n",
    "        dur.append(t1 - t0)\n",
    "    train_acc = th.sum(logits[train_mask].argmax(dim=1) == labels[train_mask]).item() / len(train_mask)\n",
    "    val_loss = F.cross_entropy(logits[val_mask], labels[val_mask])\n",
    "    val_acc = th.sum(logits[val_mask].argmax(dim=1) == labels[val_mask]).item() / len(val_mask)\n",
    "    print(\"Epoch {:05d} | Train Acc: {:.4f} | Train Loss: {:.4f} | Valid Acc: {:.4f} | Valid loss: {:.4f} | Time: {:.4f}\".\n",
    "          format(epoch, train_acc, loss.item(), val_acc, val_loss.item(), np.average(dur)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765b2c12-ea49-4355-a9db-05d3aabf560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "logits = model.forward()[category]\n",
    "test_loss = F.cross_entropy(logits[test_mask], labels[test_mask])\n",
    "test_acc = th.sum(logits[test_mask].argmax(dim=1) == labels[test_mask]).item() / len(test_mask)\n",
    "print(\"Test Acc: {:.4f} | Test loss: {:.4f}\".format(test_acc, test_loss.item()))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14180a5-8a78-4eb5-b607-8a355010b550",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
